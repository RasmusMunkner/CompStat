---
title: "Stochastic Optimization"
author: "Rasmus V. Munkner"
format: revealjs
---

## Problem statement
We consider the issue of minimizing a penalized, negative loglikelihhood

$$
H(\beta) = -\frac{1}{N}\sum_{i=1}^N\left(y_i\log p_i(\beta) + (1-y_i)\log(1-p_i(\beta))\right) + \lambda||f_\beta''||_2^2
$$
where
$$
\text{logit}(p_i(\beta)) = f(x_i\mid \beta) = \varphi(x_i)^T\beta
$$

## Some mathematical details {style="font-size: 35%"}
Note that
$$
||f''_\beta||_2^2 =
\int f''_\beta(x)^2dx =
\int \left(\sum_{k=1}^p \varphi_k''(x)\beta_k\right)^2 dx =
\sum_{k = 1}^p \sum_{j = 1}^p \beta_k \beta_j\int \varphi_k(x)''\varphi_j(x)'' dx =
\sum_{k = 1}^p \sum_{j = 1}^p \beta_k \beta_j \langle\varphi_k'',\varphi_j''\rangle :=
\beta^T \Omega \beta
$$

Also
$$
\log(p_i(\beta)) =
\log\left(\frac{e^{\varphi(x_i)^T\beta}}{1+e^{\varphi(x_i)^T\beta}}\right) =
\varphi_i(x)^T\beta - \log\left(1 + e^{\varphi(x_i)^T\beta}\right) \\
\log(1-p_i(\beta)) =
\log\left(1 - \frac{e^{\varphi(x_i)^T\beta}}{1+e^{\varphi(x_i)^T\beta}}\right) =
-\log\left(1 + e^{\varphi(x_i)^T\beta}\right)
$$

Hence
$$
\nabla_\beta \log(p_i(\beta)) =
\varphi(x_i) - \frac{e^{\varphi(x_i)^T\beta}}{1 + e^{\varphi(x_i)^T\beta}}\varphi(x_i) =
\frac{1}{1 + e^{\varphi(x_i)^T\beta}}\varphi(x_i) \\
\nabla_\beta \log(1 - p_i(\beta)) =
-\frac{e^{\varphi(x_i)^T\beta}}{1 + e^{\varphi(x_i)^T\beta}}\varphi(x_i)
$$

Thus
$$
\nabla_\beta H(\beta) =
-\frac{1}{N}\sum_{i=1}^N\left( \frac{y_i}{1 + e^{\varphi(x_i)^T\beta}}\varphi(x_i) - \frac{(1-y_i)e^{\varphi(x_i)^T\beta}}{1 + e^{\varphi(x_i)^T\beta}}\varphi(x_i)\right) + 2\lambda \Omega\beta := \\
-\frac{1}{N}\sum_{i=1}^N \left(\frac{y_i + (1-y_i)\eta_i}{1+\eta_i}\right)\varphi(x_i) + 2\lambda \Omega \beta =
-\frac{1}{N}\sum_{i=1}^N \left(\frac{\eta_i}{1 + \eta_i} + y_i\frac{1-\eta_i}{1+\eta_i}\right)\varphi(x_i) + 2\lambda \Omega \beta
$$

## On the calculation of $\Omega$ {.smaller}
To calculate the penalty matrix, we should evaluate
$$
\Omega_{ij} = \int_{-\infty}^{\infty} \varphi_i''(x)\varphi_j''(x)dx = \sum_{m = 1}^{n} \int_{k_{m-1}}^{k_m} \varphi_i''(x)\varphi_j''(x) dx := \sum_{m = 1}^{n} \int_{k_{m-1}}^{k_m} g_{ij}(x) dx
$$
Where we used that we don't care to penalize outside the boundary knots $k_0$ and $k_m$. This could for example be achieved by using natural splines.

Note that for $\varphi_i$ a 3-degree spline, $\varphi_i$ is linear between any two knots $k_{m-1}$, $k_{m}$ and thus $g_{ij}$ is a quadratic on this interval. Hence the Simpson-integration rule
$$
\int_a^b g_{ij}(x)dx = \frac{b-a}{6}\left(g_{ij}(a) + 4g_{ij}\left(\frac{a+b}{2}\right) + g_{ij}(b)\right)
$$
is an exact equality.












