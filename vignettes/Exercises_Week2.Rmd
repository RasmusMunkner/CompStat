---
title: "Exercises_Week2"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Exercises_Week2}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(CompStat)
library(magrittr)
library(ggplot2)
```

# Exercise 2.1
We have that
$$\int_{-1}^1 K(x)dx =
\int_{-1}^1 \frac{3}{4}(1-x^2)dx =
\frac{3}{2}\int_0^1 1 - x^2dx =
\frac{3}{2}[x - \frac{1}{3}x^3]_0^1 =
1
$$
Thus showing that $K$ is a density. For the mean
$$
\int_{-1}^1 xK(x)dx =
\frac{3}{4}\int_{-1}^1 x - x^3 dx =
0
$$
Since the symmetric integral of an odd function is always 0. For $\sigma_K^2$, we get
$$
\sigma_K^2 =
\int_{-1}^1 x^2K(x)dx =
\frac{3}{2}\int_0^1 x^2 - x^4 dx =
\frac{3}{2}[\frac{1}{3}x^3 - \frac{1}{5}x^5]_0^1 =
\frac{3}{2} \cdot \frac{2}{15} =
\frac{1}{5}
$$
Finally, for the L2-norm, we get
$$
||K||_2^2 =
\int_{-1}^1 K^2(x)dx =
\frac{9}{16}\int_{-1}^1 (1-x^2)^2dx =
\frac{9}{8}\int_{-1}^0 1 - 2x^2 + x^4dx = \\
\frac{9}{8}[x - \frac{2}{3}x^3 + \frac{1}{5}x^5]_0^1 =
\frac{9}{8}(1 - \frac{2}{3} + \frac{1}{5}) =
\frac{9}{8} \cdot \frac{8}{15} =
\frac{3}{5}
$$

# Exercise 2.2

```{r}
data(infrared)
F12 <- log(infrared$F12)
dens <- c(0.01, 0.05, 0.1, 0.2, 0.5, 1) %>% 
  purrr::map(.f=function(bw){
    density(F12, bw = bw, kernel="epanechnikov")
  })
for (i in 1:length(dens)){
  plot(dens[[i]])
}
```
# Exercise 2.3
Going to try to use the functionality we have implemented ourselves.

```{r}
replications <- dens %>% 
  purrr::map(.f = function(d){
    tibble::tibble(
      x = d$x,
      y = compile_density(d$x, F12, bw=d$bw, kernel_code="e")
    )
  })

ggplot(mapping = aes(x = dens[[3]]$x)) +
  geom_line(aes(y = dens[[3]]$y)) +
  geom_line(aes(y = replications[[3]]$y), color = "red")

```

Really, this is not too great. Should ask my TA.

# Exercise 2.4

```{r}
x <- rnorm(2^13)
calls <- seq(5,13) %>% 
  purrr:::map(.f=function(z){
    paste0("density(x[1:", 2^z, "], 0.2)") %>% 
      parse(text=.)
  })
names(calls) <- seq(5,13)
results <- microbenchmark::microbenchmark(
  calls[[1]],
  calls[[2]],
  calls[[3]],
  calls[[4]],
  calls[[5]],
  calls[[6]],
  calls[[7]],
  calls[[8]],
  calls[[9]],
  times=10000
)
autoplot(results)

x1 <- rnorm(128)
x2 <- rnorm(8196)
microbenchmark::microbenchmark(density(x1, 0.2), density(x2, 0.2), calls[[1]])

```

This aint great either. IDK why it does not work.

# Exercise 2.5

```{r}
test_run <- density(F12, bw=0.02)
microbenchmark::microbenchmark(
  density(F12, bw= 0.02),
  compile_density(z = test_run$x, F12, bw=0.02, kernel_code = "e")
)
```
Yea, better look into that.

# Exercise 2.6
Just a simple test.
```{r}
microbenchmark::microbenchmark(
  density(F12, bw = 0.02, kernel="gaussian"),
  density(F12, bw = 0.02, kernel="epanechnikov")
) %>% 
  autoplot()
```
Kernels seem to be equally fast. Not much of a difference really.
Could try to change the bw or number of points for estimation.







